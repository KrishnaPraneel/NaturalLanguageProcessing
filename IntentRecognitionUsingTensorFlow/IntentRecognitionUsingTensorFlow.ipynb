{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f05c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "import numpy as np \n",
    "import random \n",
    "import json \n",
    "  \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "726708d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['intents'])\n",
      "<class 'list'>\n",
      "22\n",
      "dict_keys(['intent', 'text', 'responses', 'extension', 'context', 'entityType', 'entities'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'intent': 'SelfAware',\n",
       " 'text': ['Can you prove you are self-aware',\n",
       "  'Can you prove you are self aware',\n",
       "  'Can you prove you have a conscious',\n",
       "  'Can you prove you are self-aware please',\n",
       "  'Can you prove you are self aware please',\n",
       "  'Can you prove you have a conscious please',\n",
       "  'prove you have a conscious'],\n",
       " 'responses': ['That is an interesting question, can you prove that you are?',\n",
       "  'That is an difficult question, can you prove that you are?',\n",
       "  'That depends, can you prove that you are?'],\n",
       " 'extension': {'function': '', 'entities': False, 'responses': []},\n",
       " 'context': {'in': '', 'out': '', 'clear': False},\n",
       " 'entityType': 'NA',\n",
       " 'entities': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/Users/krishnapeddibhotla/Downloads/Intent.json', 'r') as f: \n",
    "data = json.load(f) \n",
    "\n",
    "print(data.keys()) \n",
    "print(type(data['intents'])) \n",
    "print(len(data['intents'])) \n",
    "print(data['intents'][0].keys()) \n",
    "data['intents'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a78a366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(line): \n",
    "    cleaned_line = '' \n",
    "    for char in line: \n",
    "        if char.isalpha(): \n",
    "            cleaned_line += char \n",
    "        else: \n",
    "            cleaned_line += ' '\n",
    "    cleaned_line = ' '.join(cleaned_line.split()) \n",
    "    return cleaned_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17d44976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of intents \n",
    "intents = []                                             \n",
    "unique_intents = [] \n",
    "#all text data to create a corpus \n",
    "text_input= []     \n",
    "#dictionary mapping intent with appropriate response \n",
    "response_for_intent = {}                                 \n",
    "for intent in data['intents']: \n",
    "    #list of unique intents \n",
    "    if intent['intent'] not in unique_intents:             \n",
    "        unique_intents.append(intent['intent'])   \n",
    "    for text in intent['text']: \n",
    "        #cleaning is done before adding text to corpus \n",
    "        text_input.append(clean(text))                     \n",
    "        intents.append(intent['intent']) \n",
    "    if intent['intent'] not in response_for_intent: \n",
    "        response_for_intent[intent['intent']] = []  \n",
    "    for response in intent['responses']: \n",
    "        response_for_intent[intent['intent']].append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb19abc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent : Greeting\n",
      "Number of Intent: 143\n",
      "Sample Input: Hi\n",
      "Length of text_input: 143\n",
      "Sample Response:  ['Hi human, please tell me your GeniSys user', 'Hello human, please tell me your GeniSys user', 'Hola human, please tell me your GeniSys user']\n"
     ]
    }
   ],
   "source": [
    "print(\"Intent :\",intents[0]) \n",
    "print(\"Number of Intent:\",len(intents)) \n",
    "print(\"Sample Input:\", text_input[0]) \n",
    "print('Length of text_input:',len(text_input)) \n",
    "print(\"Sample Response: \", response_for_intent[intents[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91c9be94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input Sequence: (143, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0, 52],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 52, 53],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 68],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 39],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 39, 53]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters='',oov_token='<unk>') \n",
    "tokenizer.fit_on_texts(text_input) \n",
    "sequences = tokenizer.texts_to_sequences(text_input) \n",
    "padded_sequences = pad_sequences(sequences, padding='pre') \n",
    "print('Shape of Input Sequence:',padded_sequences.shape) \n",
    "padded_sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d51d7e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Intents : 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'Greeting',\n",
       " 1: 'GreetingResponse',\n",
       " 2: 'CourtesyGreeting',\n",
       " 3: 'CourtesyGreetingResponse',\n",
       " 4: 'CurrentHumanQuery',\n",
       " 5: 'NameQuery',\n",
       " 6: 'RealNameQuery',\n",
       " 7: 'TimeQuery',\n",
       " 8: 'Thanks',\n",
       " 9: 'NotTalking2U',\n",
       " 10: 'UnderstandQuery',\n",
       " 11: 'Shutup',\n",
       " 12: 'Swearing',\n",
       " 13: 'GoodBye',\n",
       " 14: 'CourtesyGoodBye',\n",
       " 15: 'WhoAmI',\n",
       " 16: 'Clever',\n",
       " 17: 'Gossip',\n",
       " 18: 'Jokes',\n",
       " 19: 'PodBayDoor',\n",
       " 20: 'PodBayDoorResponse',\n",
       " 21: 'SelfAware'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_to_index = {} \n",
    "categorical_target = [] \n",
    "index = 0\n",
    "  \n",
    "for intent in intents: \n",
    "    if intent not in intent_to_index: \n",
    "        intent_to_index[intent] = index \n",
    "        index += 1\n",
    "    categorical_target.append(intent_to_index[intent]) \n",
    "  \n",
    "num_classes = len(intent_to_index) \n",
    "print('Number of Intents :',num_classes) \n",
    "  \n",
    "# Convert intent_to_index to index_to_intent \n",
    "index_to_intent = {index: intent for intent, index in intent_to_index.items()} \n",
    "index_to_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "481d961b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Ca (143, 22)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_vec = tf.keras.utils.to_categorical(categorical_target,  \n",
    "                                                num_classes=num_classes, dtype='int32') \n",
    "  \n",
    "print('Shape of Ca',categorical_vec.shape) \n",
    "categorical_vec[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69fbba67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Dimension :22,\n",
      "Output Dimension :22\n"
     ]
    }
   ],
   "source": [
    "epochs=100\n",
    "embed_dim=300\n",
    "lstm_num=50\n",
    "output_dim=categorical_vec.shape[1] \n",
    "input_dim=len(unique_intents) \n",
    "print(\"Input Dimension :{},\\nOutput Dimension :{}\".format(input_dim,output_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a03accd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 300)         35700     \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 100)               140400    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                5050      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 22)                1122      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 182272 (712.00 KB)\n",
      "Trainable params: 182272 (712.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([ \n",
    "    tf.keras.layers.Embedding(len(tokenizer.word_index) + 1, embed_dim), \n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_num, dropout=0.1)),   \n",
    "    tf.keras.layers.Dense(lstm_num, activation='relu'), \n",
    "    tf.keras.layers.Dropout(0.4), \n",
    "    tf.keras.layers.Dense(output_dim, activation='softmax') \n",
    "]) \n",
    "  \n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001)   \n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faabf481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x30f5aff50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_sequences, categorical_vec, epochs=epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3535a236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 332ms/step - loss: 0.1902 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "test_text_inputs = [\"Hello\",  \n",
    "                    \"my name is adam\",  \n",
    "                    \"how are you?\",  \n",
    "                    \"can you guess my name?\", \n",
    "                    \"Do you get me\",\"Adios\"] \n",
    "  \n",
    "test_intents = [\"Greeting\", \n",
    "                \"GreetingResponse\", \n",
    "                \"CourtesyGreeting\", \n",
    "                \"CurrentHumanQuery\", \n",
    "                \"UnderstandQuery\", \n",
    "                \"GoodBye\"] \n",
    "  \n",
    "test_sequences = tokenizer.texts_to_sequences(test_text_inputs) \n",
    "test_padded_sequences = pad_sequences(test_sequences,  padding='pre') \n",
    "test_labels = np.array([unique_intents.index(intent) for intent in test_intents]) \n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes) \n",
    "loss, accuracy = model.evaluate(test_padded_sequences, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30fa275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(sentence): \n",
    "    sent_tokens = [] \n",
    "    # Split the input sentence into words \n",
    "    words = sentence.split() \n",
    "    # Convert words to their corresponding word indices \n",
    "    for word in words:                                            \n",
    "        if word in tokenizer.word_index: \n",
    "            sent_tokens.append(tokenizer.word_index[word]) \n",
    "        else: \n",
    "            # Handle unknown words \n",
    "            sent_tokens.append(tokenizer.word_index['<unk>']) \n",
    "    sent_tokens = tf.expand_dims(sent_tokens, 0) \n",
    "    #predict numerical category \n",
    "    pred = model(sent_tokens)     \n",
    "    #category to intent \n",
    "    pred_class = np.argmax(pred.numpy(), axis=1)                 \n",
    "    # random response to that intent \n",
    "    return random.choice( \n",
    "        response_for_intent[index_to_intent[pred_class[0]]]), index_to_intent[pred_class[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a230d0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Enter 'quit' to break the loop.\n",
      "You: hey\n",
      "Geek: Cool! Hello <HUMAN>, what can I do for you? -- TYPE: CourtesyGreetingResponse\n",
      "\n",
      "You: my name is krishna praneel\n",
      "Geek: Your name is  <HUMAN>, how can I help you? -- TYPE: CurrentHumanQuery\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Note: Enter 'quit' to break the loop.\")    \n",
    "while True:                                                 \n",
    "    query = input('You: ') \n",
    "    if query.lower() == 'quit': \n",
    "        break\n",
    "    bot_response, typ = response(query) \n",
    "    print('Geek: {} -- TYPE: {}'.format(bot_response, typ)) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3676bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
